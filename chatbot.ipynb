{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5345170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c1ee84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000019BE5CF86A0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000019BE5CF85B0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model='llama-3.1-8b-instant',groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a5cd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI engineer, you must be working on developing and implementing artificial intelligence and machine learning models to solve real-world problems. That's a fascinating field.\\n\\nWhat specific areas of AI engineering are you interested in or working on? Are you more focused on:\\n\\n1. Natural Language Processing (NLP)?\\n2. Computer Vision?\\n3. Robotics?\\n4. Deep Learning?\\n5. Reinforcement Learning?\\n6. Something else?\\n\\nOr perhaps you're working on a specific project or application, such as:\\n\\n1. Healthcare?\\n2. Finance?\\n3. Autonomous vehicles?\\n4. Education?\\n\\nI'm here to chat and help if you'd like to discuss anything related to AI engineering.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 137, 'prompt_tokens': 40, 'total_tokens': 177, 'completion_time': 0.194217607, 'prompt_time': 0.001804478, 'queue_time': 0.052402962, 'total_time': 0.196022085}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_e750f72ec9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--ee9e39c6-d6b3-43e1-bdee-fb81f8bf71a6-0', usage_metadata={'input_tokens': 40, 'output_tokens': 137, 'total_tokens': 177})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content='Hi i am ai engineer')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d0a3975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI engineer, your tasks can vary depending on the specific project or company you're working with. Here are some common responsibilities:\\n\\n1. **Design and develop AI models**: You'll work on designing, implementing, and testing AI models using programming languages like Python, Java, or C++.\\n2. **Data preprocessing**: Collecting, cleaning, and preprocessing data to prepare it for training AI models.\\n3. **Model training and optimization**: Training AI models using machine learning algorithms and optimizing their performance.\\n4. **Model deployment**: Deploying AI models in production environments, such as web applications or mobile apps.\\n5. **Collaborate with cross-functional teams**: Working with data scientists, product managers, and software engineers to integrate AI models into products.\\n6. **Troubleshooting and debugging**: Identifying and fixing issues with AI models or their deployment.\\n7. **Staying up-to-date with industry trends**: Keeping current with the latest advancements in AI and machine learning.\\n\\nWhat specific area of AI engineering are you interested in or currently working on? (e.g., computer vision, natural language processing, robotics, etc.)?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 230, 'prompt_tokens': 86, 'total_tokens': 316, 'completion_time': 0.272501188, 'prompt_time': 0.004606779, 'queue_time': 0.051722191, 'total_time': 0.277107967}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--ccc9dae5-250b-474c-ac22-f2e883abed2c-0', usage_metadata={'input_tokens': 86, 'output_tokens': 230, 'total_tokens': 316})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi i am ai engineer\"),\n",
    "    AIMessage(content=\"As an AI engineer, you must be working on developing and implementing artificial intelligence and machine learning models to solve real-world problems. That's a fascinating field\"),\n",
    "    HumanMessage(content=\"hello what do i do?\")\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd4cc1",
   "metadata": {},
   "source": [
    "### Message History\n",
    "we can use a message history class to wrap our model and make it stateful. This will keep track of \n",
    "inputs and output of model,and store them in datastore.Future interactions will load them messages \n",
    "and pass them into the chain as part of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a165dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory #stores messages in memory list   \n",
    "from langchain_core.chat_history import BaseChatMessageHistory #abstract base class for storing chat message history\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory #manages chatmessagehistory for another runnable\n",
    "\n",
    "store={}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae0eed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "354ec150",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aae21d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Ai engineer, what brings you here today? Are you working on a new project, seeking advice on a specific topic, or looking to discuss the latest advancements in the field of artificial intelligence? I'm all ears, and I'd be happy to help or engage in a conversation about AI. \\n\\nWhat type of AI projects are you involved with? Are you focusing on NLP, computer vision, reinforcement learning, or something else?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 41, 'total_tokens': 129, 'completion_time': 0.15081157, 'prompt_time': 0.00217055, 'queue_time': 0.05479311, 'total_time': 0.15298212}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--1177b8f8-6214-4546-a516-f2712f3c554f-0', usage_metadata={'input_tokens': 41, 'output_tokens': 88, 'total_tokens': 129})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, i am Ai engineer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "572bb24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an AI engineer.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"who am i?\")],\n",
    "    config=config\n",
    ")\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b9a9b",
   "metadata": {},
   "source": [
    "### Prompt Templates\n",
    "prompt template help to turn raw information into a format that llm can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe9375e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system','you are helpful assistant. Answer all the question'),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94b3d5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Sushant. I'm happy to assist you with any questions or information you may need. How's your day going so far?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 51, 'total_tokens': 84, 'completion_time': 0.048269065, 'prompt_time': 0.002460466, 'queue_time': 0.050687963, 'total_time': 0.050729531}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--08e537bd-f2ec-4d1a-8a57-41c58a12ace9-0', usage_metadata={'input_tokens': 51, 'output_tokens': 33, 'total_tokens': 84})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'messages':[HumanMessage(content=\"hi my name is sushant\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9c04380",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b010dc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Sushant! It's a pleasure to chat with you again. How's your day going so far?\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={'configurable':{'session_id':'chat3'}}\n",
    "response=with_message_history.invoke([\n",
    "    HumanMessage(content='hi my name is sushant')\n",
    "],config=config)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9d2e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4384eeb6",
   "metadata": {},
   "source": [
    "### Managing the conversation history\n",
    "when building chatbots, need to manage conversation history.If left unmanaged, the list of messages\n",
    "will grow unbounded and potentially overflow the context window of LLM.Therfore, it is important to\n",
    "add a step to limits the size of the messages you are passing in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b8caa58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You ara a good assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like icecream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is 2+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trim_messages=helps to reduce how many msg we're sending to the model (reduce size of chat history)\n",
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy='last',\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages=[\n",
    "    SystemMessage(content='You ara a good assistant.'),\n",
    "    HumanMessage(content='Hi! i am vijay'),\n",
    "    AIMessage(content='Hi!'),\n",
    "    HumanMessage(content='I like icecream'),\n",
    "    AIMessage(content='nice'),\n",
    "    HumanMessage(content='what is 2+2'),\n",
    "    AIMessage(content='4'),\n",
    "    HumanMessage(content='thanks'),\n",
    "    AIMessage(content='no problem!')\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff32a253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You mentioned earlier that you like ice cream!'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter('messages')|trimmer)\n",
    "    |prompt\n",
    "    |model\n",
    ")\n",
    "\n",
    "response=chain.invoke({\n",
    "    \"messages\":messages + [HumanMessage(content=\"which food do i like?\")],\n",
    "    \"language\":\"English\",\n",
    "})\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
